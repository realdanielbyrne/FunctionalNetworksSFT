# Financial Instruction-Following Evaluation Configuration
# Adapted for ICA comparison experiment

# Model configuration (will be overridden by comparison script)
model_name_or_path: "meta-llama/Llama-3.2-1B-Instruct"
use_auth_token: true
trust_remote_code: true
torch_dtype: "auto"

# Output configuration
output_dir: "./evaluation_results/financial"
run_name: "financial_instruction_evaluation"

# Performance settings (optimized for comprehensive evaluation)
batch_size: 8
max_length: 1024
num_workers: 4

# Reporting settings
generate_report: true
include_visualizations: true
save_predictions: true

# Logging
log_level: "INFO"
use_wandb: false

# Benchmarks configuration (focused on financial instruction-following)
benchmarks:
  # Language Understanding (financial context)
  - name: "language_understanding"
    enabled: true
    max_samples: 200  # Increased for better statistical significance
    batch_size: 8
    metrics:
      - name: "perplexity"
        enabled: true
      - name: "bleu"
        enabled: true
      - name: "rouge"
        enabled: true
      - name: "bertscore"
        enabled: true

  # MMLU (focus on relevant subjects)
  - name: "mmlu"
    enabled: true
    dataset_name: "cais/mmlu"
    max_samples: 500  # Increased for better coverage
    batch_size: 8
    subjects: ["econometrics", "business_ethics", "professional_accounting", "miscellaneous"]
    metrics:
      - name: "mmlu_accuracy"
        enabled: true

  # Financial Reasoning (custom evaluation)
  - name: "financial_reasoning"
    enabled: true
    max_samples: 100
    batch_size: 4
    metrics:
      - name: "accuracy"
        enabled: true
      - name: "f1_score"
        enabled: true
    parameters:
      max_length: 512
      max_new_tokens: 100
      temperature: 0.1  # Low temperature for consistent reasoning

  # Instruction Following Quality
  - name: "instruction_following"
    enabled: true
    max_samples: 150
    batch_size: 4
    metrics:
      - name: "instruction_adherence"
        enabled: true
      - name: "response_quality"
        enabled: true
    parameters:
      max_length: 1024
      max_new_tokens: 200
      temperature: 0.3

  # Performance metrics
  - name: "performance"
    enabled: true
    max_samples: 50
    batch_size: 4
    metrics:
      - name: "inference_speed"
        enabled: true
      - name: "memory_usage"
        enabled: true
      - name: "model_size"
        enabled: true
      - name: "throughput"
        enabled: true
    parameters:
      max_length: 512
      max_new_tokens: 50

  # Safety and Bias Evaluation
  - name: "safety_evaluation"
    enabled: true
    max_samples: 100
    batch_size: 8
    metrics:
      - name: "toxicity_score"
        enabled: true
      - name: "bias_detection"
        enabled: true
    parameters:
      max_length: 512
      max_new_tokens: 100

# Custom evaluation parameters for financial domain
financial_evaluation:
  # Financial concepts to test
  concepts:
    - "risk_assessment"
    - "portfolio_management"
    - "financial_planning"
    - "investment_analysis"
    - "market_analysis"
    - "regulatory_compliance"
  
  # Evaluation criteria
  criteria:
    accuracy: 0.3      # Weight for factual accuracy
    relevance: 0.25    # Weight for domain relevance
    clarity: 0.2       # Weight for explanation clarity
    completeness: 0.15 # Weight for response completeness
    safety: 0.1        # Weight for safety/compliance

# Comparison-specific settings
comparison:
  enable_detailed_analysis: true
  save_intermediate_results: true
  generate_diff_report: true
  statistical_significance_test: true
