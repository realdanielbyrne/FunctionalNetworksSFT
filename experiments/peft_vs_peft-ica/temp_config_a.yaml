model_name_or_path: WeiboAI/VibeThinker-1.5B
torch_dtype: auto
use_4bit: false
use_8bit: false
attn_implementation: auto
dataset_name_or_path: camel-ai/physics
validation_split: 0.1
response_max_length: 10000
instruction_max_length: 5000
lora_r: 16
lora_alpha: 32
lora_dropout: 0
lora_target_modules: null
num_train_epochs: 1
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 1
learning_rate: 0.0002
weight_decay: 0.0001
warmup_ratio: 0.05
lr_scheduler_type: cosine
max_seq_length: 4196
template_format: auto
logging_steps: 100
save_steps: 1000
eval_steps: 1000
save_total_limit: 2
load_best_model_at_end: true
metric_for_best_model: eval_loss
evaluation_strategy: steps
gradient_checkpointing: false
use_wandb: true
push_to_hub: false
hub_private: false
merge_adapter_with_base: true
upload_merged_model: true
resume_from_checkpoint: null
convert_to_gguf: false
anti_drift_apply_to: both
use_auth_token: true
output_dir: experiments/peft_vs_peft-ica/experiment_a_peft_only/output
wandb_project: VibeThinker-1.5B-Physics-PEFT-Only
hub_repo_id: realdanielbyrne/VibeThinker-1.5B-Physics
hub_commit_message: 1 Epoch Physics, PEFT Only
mask_mode: null
