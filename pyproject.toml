[project]
name = "functionalnetworkssft"
version = "0.1.0"
description = ""
authors = [
    {name = "Daniel Byrne",email = "realdanielbyrne@icloud.com"}
]
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    # Core ML frameworks with cross-platform support
    # Note: PyTorch installation is handled by optional dependencies for platform-specific versions

    # Hugging Face ecosystem
    "transformers>=4.40.0,<5.0.0",  # Core transformers library
    "datasets>=2.18.0",             # Dataset loading and processing
    "tokenizers>=0.19.0",           # Fast tokenizers
    "accelerate>=0.30.0",           # Training acceleration
    "peft>=0.10.0",                 # Parameter-efficient fine-tuning (LoRA/QLoRA)

    # Model hub and experiment tracking
    "huggingface-hub>=0.22.0",      # Model hub integration
    "wandb>=0.16.0",                # Experiment tracking

    # Utilities
    "tqdm>=4.65.0",                 # Progress bars
    "pyyaml>=6.0",                  # YAML configuration files
    "numpy>=1.24.0,<2.0.0",        # Numerical computing
    "scipy>=1.10.0",                # Scientific computing
    "scikit-learn>=1.3.0",          # Machine learning utilities (for ICA)
    "safetensors>=0.4.0",           # Safe tensor serialization

    # Development and testing
    "pytest>=7.0.0",               # Testing framework
    "black>=23.0.0",               # Code formatting
    "isort>=5.12.0",               # Import sorting
    "mypy>=1.0.0",                 # Type checking
    "openai (>=1.97.1,<2.0.0)",
    "lm-eval (>=0.4.9,<0.5.0)",
    "evaluate (>=0.4.5,<0.5.0)",
    "nltk (>=3.9.1,<4.0.0)",
    "rouge-score (>=0.1.2,<0.2.0)",
]

[project.scripts]
fnsft = "functionalnetworkssft.fnsft_trainer:main"
check-hf-token = "functionalnetworkssft.check_hf_token:main"

[project.optional-dependencies]
# CPU-only PyTorch (fallback for any platform)
cpu = [
    "torch>=2.4.0,<2.8.0",         # PyTorch CPU-only version
    "torchvision>=0.19.0",         # Vision utilities
    "torchaudio>=2.4.0",           # Audio utilities
]

# CUDA-enabled PyTorch for NVIDIA GPUs (Windows/Linux)
# Note: These use Poetry's URL dependency syntax to install from PyTorch's CUDA index
cuda = [
    "torch>=2.4.0,<2.8.0",         # PyTorch with CUDA support
    "torchvision>=0.19.0",         # Vision utilities with CUDA
    "torchaudio>=2.4.0",           # Audio utilities with CUDA
    "bitsandbytes>=0.43.0",        # Quantization library (CUDA only)
    "flash-attn>=2.5.0",           # Flash attention (CUDA only)
]

# Apple Silicon optimizations (includes MPS support)
apple-silicon = [
    "torch>=2.4.0,<2.8.0",         # PyTorch with MPS support for Apple Silicon
    "torchvision>=0.19.0",         # Vision utilities
    "torchaudio>=2.4.0",           # Audio utilities
    # Note: bitsandbytes and flash-attn are not compatible with Apple Silicon
]

# Development dependencies
dev = [
    "jupyter>=1.0.0",              # Jupyter notebooks
    "ipywidgets>=8.0.0",           # Jupyter widgets
    "matplotlib>=3.7.0",          # Plotting
    "seaborn>=0.12.0",             # Statistical plotting
]

# All optional dependencies for CUDA systems
all-cuda = [
    # PyTorch with CUDA (install from pytorch-cuda source)
    "torch>=2.4.0,<2.8.0",
    "torchvision>=0.19.0",
    "torchaudio>=2.4.0",
    # CUDA-specific optimizations
    "bitsandbytes>=0.43.0",
    "flash-attn>=2.5.0",
    # Dev dependencies
    "jupyter>=1.0.0",
    "ipywidgets>=8.0.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
]

# All optional dependencies for Apple Silicon
all-apple = [
    # PyTorch with MPS
    "torch>=2.4.0,<2.8.0",
    "torchvision>=0.19.0",
    "torchaudio>=2.4.0",
    # Dev dependencies
    "jupyter>=1.0.0",
    "ipywidgets>=8.0.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
]

# All optional dependencies for CPU-only systems
all-cpu = [
    # PyTorch CPU-only
    "torch>=2.4.0,<2.8.0",
    "torchvision>=0.19.0",
    "torchaudio>=2.4.0",
    # Dev dependencies
    "jupyter>=1.0.0",
    "ipywidgets>=8.0.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
]

[tool.poetry]
packages = [{include = "functionalnetworkssft", from = "src"}]

# Note: CUDA PyTorch installation is handled by scripts/setup_cuda.py
# which uses the appropriate PyTorch CUDA index for the platform

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"
